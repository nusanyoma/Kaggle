{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime, math\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = True\n",
    "MAKE_MODEL_TEST = True\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model params\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':80000,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import lightgbm as lgb\n",
    "\n",
    "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "\n",
    "    tt_df = tt_df[['TransactionID',target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            vl_data = lgb.Dataset(P, label=P_y) \n",
    "        else:\n",
    "            vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    \n",
    "    return tt_df\n",
    "\n",
    "def make_test_predictions(tr_df, tt_df, target, lgb_params, NFOLDS=2):\n",
    "    \n",
    "    new_columns = set(list(train_df)).difference(base_columns + remove_features)\n",
    "    features_columns = base_columns + list(new_columns)\n",
    "    \n",
    "    folds = KFold(n_splits=NFOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "\n",
    "    for col in list(X):\n",
    "        if X[col].dtype=='O':\n",
    "            X[col] = X[col].fillna('unseen_before_label')\n",
    "            P[col] = P[col].fillna('unseen_before_label')\n",
    "\n",
    "            X[col] = train_df[col].astype(str)\n",
    "            P[col] = test_df[col].astype(str)\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            le.fit(list(X[col])+list(P[col]))\n",
    "            X[col] = le.transform(X[col])\n",
    "            P[col]  = le.transform(P[col])\n",
    "\n",
    "            X[col] = X[col].astype('category')\n",
    "            P[col] = P[col].astype('category')\n",
    "        \n",
    "    tt_df = tt_df[['TransactionID',target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "\n",
    "    tr_data = lgb.Dataset(X, label=y)\n",
    "    vl_data = lgb.Dataset(P, label=P_y) \n",
    "    estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "    pp_p = estimator.predict(P)\n",
    "    predictions += pp_p/NFOLDS\n",
    "\n",
    "    if LOCAL_TEST:\n",
    "        feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "        print(feature_imp)\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    \n",
    "    return tt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values_normalization(dt_df, periods, columns):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            dt_df[col] = dt_df[col].astype(float)  \n",
    "\n",
    "            temp_min = dt_df.groupby([period])[col].agg(['min']).reset_index()\n",
    "            temp_min.index = temp_min[period].values\n",
    "            temp_min = temp_min['min'].to_dict()\n",
    "\n",
    "            temp_max = dt_df.groupby([period])[col].agg(['max']).reset_index()\n",
    "            temp_max.index = temp_max[period].values\n",
    "            temp_max = temp_max['max'].to_dict()\n",
    "\n",
    "            temp_mean = dt_df.groupby([period])[col].agg(['mean']).reset_index()\n",
    "            temp_mean.index = temp_mean[period].values\n",
    "            temp_mean = temp_mean['mean'].to_dict()\n",
    "\n",
    "            temp_std = dt_df.groupby([period])[col].agg(['std']).reset_index()\n",
    "            temp_std.index = temp_std[period].values\n",
    "            temp_std = temp_std['std'].to_dict()\n",
    "\n",
    "            dt_df['temp_min'] = dt_df[period].map(temp_min)\n",
    "            dt_df['temp_max'] = dt_df[period].map(temp_max)\n",
    "            dt_df['temp_mean'] = dt_df[period].map(temp_mean)\n",
    "            dt_df['temp_std'] = dt_df[period].map(temp_std)\n",
    "\n",
    "            dt_df[new_col+'_min_max'] = (dt_df[col]-dt_df['temp_min'])/(dt_df['temp_max']-dt_df['temp_min'])\n",
    "            dt_df[new_col+'_std_score'] = (dt_df[col]-dt_df['temp_mean'])/(dt_df['temp_std'])\n",
    "            del dt_df['temp_min'],dt_df['temp_max'],dt_df['temp_mean'],dt_df['temp_std']\n",
    "    return dt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_encoding(train_df, test_df, columns, self_encoding=False):\n",
    "    for col in columns:\n",
    "        temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "        fq_encode = temp_df[col].value_counts(dropna=False).to_dict()\n",
    "        if self_encoding:\n",
    "            train_df[col] = train_df[col].map(fq_encode)\n",
    "            test_df[col]  = test_df[col].map(fq_encode)            \n",
    "        else:\n",
    "            train_df[col+'_fq_enc'] = train_df[col].map(fq_encode)\n",
    "            test_df[col+'_fq_enc']  = test_df[col].map(fq_encode)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeblock_frequency_encoding(train_df, test_df, periods, columns, \n",
    "                                 with_proportions=True, only_proportions=False):\n",
    "    for period in periods:\n",
    "        for col in columns:\n",
    "            new_col = col +'_'+ period\n",
    "            train_df[new_col] = train_df[col].astype(str)+'_'+train_df[period].astype(str)\n",
    "            test_df[new_col]  = test_df[col].astype(str)+'_'+test_df[period].astype(str)\n",
    "\n",
    "            temp_df = pd.concat([train_df[[new_col]], test_df[[new_col]]])\n",
    "            fq_encode = temp_df[new_col].value_counts().to_dict()\n",
    "\n",
    "            train_df[new_col] = train_df[new_col].map(fq_encode)\n",
    "            test_df[new_col]  = test_df[new_col].map(fq_encode)\n",
    "            \n",
    "            if only_proportions:\n",
    "                train_df[new_col] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col]  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "            if with_proportions:\n",
    "                train_df[new_col+'_proportions'] = train_df[new_col]/train_df[period+'_total']\n",
    "                test_df[new_col+'_proportions']  = test_df[new_col]/test_df[period+'_total']\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uid_aggregation(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "    return train_df, test_df\n",
    "\n",
    "def uid_aggregation_and_normalization(train_df, test_df, main_columns, uids, aggregations):\n",
    "    for main_column in main_columns:  \n",
    "        for col in uids:\n",
    "            \n",
    "            new_norm_col_name = col+'_'+main_column+'_std_norm'\n",
    "            norm_cols = []\n",
    "            \n",
    "            for agg_type in aggregations:\n",
    "                new_col_name = col+'_'+main_column+'_'+agg_type\n",
    "                temp_df = pd.concat([train_df[[col, main_column]], test_df[[col,main_column]]])\n",
    "                temp_df = temp_df.groupby([col])[main_column].agg([agg_type]).reset_index().rename(\n",
    "                                                        columns={agg_type: new_col_name})\n",
    "\n",
    "                temp_df.index = list(temp_df[col])\n",
    "                temp_df = temp_df[new_col_name].to_dict()   \n",
    "\n",
    "                train_df[new_col_name] = train_df[col].map(temp_df)\n",
    "                test_df[new_col_name]  = test_df[col].map(temp_df)\n",
    "                norm_cols.append(new_col_name)\n",
    "            \n",
    "            train_df[new_norm_col_name] = (train_df[main_column]-train_df[norm_cols[0]])/train_df[norm_cols[1]]\n",
    "            test_df[new_norm_col_name]  = (test_df[main_column]-test_df[norm_cols[0]])/test_df[norm_cols[1]]          \n",
    "            \n",
    "            del train_df[norm_cols[0]], train_df[norm_cols[1]]\n",
    "            del test_df[norm_cols[0]], test_df[norm_cols[1]]\n",
    "                                              \n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cor_and_remove(train_df, test_df, i_cols, new_columns, remove=False):\n",
    "    # Check correllation\n",
    "    print('Correlations','#'*10)\n",
    "    for col in new_columns:\n",
    "        cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "        print(col, cor_cof)\n",
    "\n",
    "    if remove:\n",
    "        print('#'*10)\n",
    "        print('Best options:')\n",
    "        best_fe_columns = []\n",
    "        for main_col in i_cols:\n",
    "            best_option = ''\n",
    "            best_cof = 0\n",
    "            for col in new_columns:\n",
    "                if main_col in col:\n",
    "                    cor_cof = np.corrcoef(train_df[TARGET], train_df[col].fillna(0))[0][1]\n",
    "                    cor_cof = (cor_cof**2)**0.5\n",
    "                    if cor_cof>best_cof:\n",
    "                        best_cof = cor_cof\n",
    "                        best_option = col\n",
    "\n",
    "            print(main_col, best_option, best_cof)            \n",
    "            best_fe_columns.append(best_option)\n",
    "\n",
    "        for col in new_columns:\n",
    "            if col not in best_fe_columns:\n",
    "                del train_df[col], test_df[col]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "Shape control: (417559, 394) (89326, 394)\n"
     ]
    }
   ],
   "source": [
    "# DATA LOAD\n",
    "print('Load Data')\n",
    "folder_path = './ieee-fraud-detection'\n",
    "train_df = pd.read_csv(f'{folder_path}/train_transaction.csv')\n",
    "\n",
    "if LOCAL_TEST:\n",
    "    \n",
    "    # Convert TransactionDT to \"Month\" time-period. \n",
    "    # We will also drop penultimate block to \"simulate\" test set values difference\n",
    "    train_df['DT_M'] = train_df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    train_df['DT_M'] = (train_df['DT_M'].dt.year-2017)*12 + train_df['DT_M'].dt.month \n",
    "    test_df = train_df[train_df['DT_M']==train_df['DT_M'].max()].reset_index(drop=True)\n",
    "    train_df = train_df[train_df['DT_M']<(train_df['DT_M'].max()-1)].reset_index(drop=True)\n",
    "    \n",
    "    train_identity = pd.read_csv(f'{folder_path}/train_identity.csv')\n",
    "    test_identity  = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    test_df['TransactionID'])].reset_index(drop=True)\n",
    "    train_identity = train_identity[train_identity['TransactionID'].isin(\n",
    "                                    train_df['TransactionID'])].reset_index(drop=True)\n",
    "    del train_df['DT_M'], test_df['DT_M']\n",
    "    \n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list of feature that we will remove later from final features list\n",
    "remove_features = ['TransactionID','TransactionDT', TARGET]\n",
    "\n",
    "base_columns = [col for col in list(train_df) if col not in remove_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.95483\tvalid_1's auc: 0.895292\n",
      "[400]\ttraining's auc: 0.982816\tvalid_1's auc: 0.910377\n",
      "[600]\ttraining's auc: 0.991732\tvalid_1's auc: 0.914128\n",
      "[800]\ttraining's auc: 0.995654\tvalid_1's auc: 0.91507\n",
      "Early stopping, best iteration is:\n",
      "[767]\ttraining's auc: 0.995211\tvalid_1's auc: 0.915216\n",
      "     Value         Feature\n",
      "0        0            V107\n",
      "1        0            V117\n",
      "2        0            V119\n",
      "3        0            V120\n",
      "4        0            V241\n",
      "5        0             V28\n",
      "6        0            V305\n",
      "7        0             V65\n",
      "8        0             V68\n",
      "9        0             V89\n",
      "10       1            V113\n",
      "11       1            V118\n",
      "12       1             V27\n",
      "13       1             V88\n",
      "14       2            V122\n",
      "15       3             V41\n",
      "16       4            V240\n",
      "17       5             V14\n",
      "18       7            V325\n",
      "19       7            V328\n",
      "20      11            V121\n",
      "21      11            V269\n",
      "22      11            V302\n",
      "23      12            V110\n",
      "24      13            V111\n",
      "25      13            V114\n",
      "26      13            V138\n",
      "27      13            V196\n",
      "28      13            V330\n",
      "29      15            V195\n",
      "..     ...             ...\n",
      "361   1525           card3\n",
      "362   1603            V313\n",
      "363   1606              M5\n",
      "364   1682              C9\n",
      "365   1697              M6\n",
      "366   1756              D9\n",
      "367   1772              M4\n",
      "368   1872             C11\n",
      "369   1950              C6\n",
      "370   2226             C14\n",
      "371   2239           dist2\n",
      "372   2389              D5\n",
      "373   2442              D3\n",
      "374   2449              C2\n",
      "375   2577             D11\n",
      "376   2865   P_emaildomain\n",
      "377   2938              C1\n",
      "378   3373              D1\n",
      "379   4028              D2\n",
      "380   4043             D10\n",
      "381   4073              D8\n",
      "382   4630              D4\n",
      "383   4686           card5\n",
      "384   4717             C13\n",
      "385   5162           dist1\n",
      "386   5657             D15\n",
      "387  10434  TransactionAmt\n",
      "388  10690           addr1\n",
      "389  11633           card2\n",
      "390  13744           card1\n",
      "\n",
      "[391 rows x 2 columns]\n",
      "0.915216348350816\n"
     ]
    }
   ],
   "source": [
    "#### Let's make baseline model \n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransactionDT\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "dates_range = pd.date_range(start='2017-10-01', end='2019-01-01')\n",
    "us_holidays = calendar().holidays(start=dates_range.min(), end=dates_range.max())\n",
    "\n",
    "# Let's add temporary \"time variables\" for aggregations and add normal \"time variables\"\n",
    "for df in [train_df, test_df]:\n",
    "    \n",
    "    # Temporary variables for aggregation\n",
    "    df['DT'] = df['TransactionDT'].apply(lambda x: (START_DATE + datetime.timedelta(seconds = x)))\n",
    "    df['DT_M'] = ((df['DT'].dt.year-2017)*12 + df['DT'].dt.month).astype(np.int8)\n",
    "    df['DT_W'] = ((df['DT'].dt.year-2017)*52 + df['DT'].dt.weekofyear).astype(np.int8)\n",
    "    df['DT_D'] = ((df['DT'].dt.year-2017)*365 + df['DT'].dt.dayofyear).astype(np.int16)\n",
    "    \n",
    "    df['DT_hour'] = (df['DT'].dt.hour).astype(np.int8)\n",
    "    df['DT_day_week'] = (df['DT'].dt.dayofweek).astype(np.int8)\n",
    "    df['DT_day_month'] = (df['DT'].dt.day).astype(np.int8)\n",
    "        \n",
    "    # Possible solo feature\n",
    "    df['is_december'] = df['DT'].dt.month\n",
    "    df['is_december'] = (df['is_december']==12).astype(np.int8)\n",
    "\n",
    "    # Holidays\n",
    "    df['is_holiday'] = (df['DT'].dt.date.astype('datetime64').isin(us_holidays)).astype(np.int8)\n",
    "\n",
    "# Remove temporary features from final list\n",
    "remove_features += ['DT','DT_M','DT_W','DT_D','DT_hour','DT_day_week','DT_day_month']\n",
    "    \n",
    "# Total transactions per timeblock\n",
    "for col in ['DT_M','DT_W','DT_D']:\n",
    "    temp_df = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    fq_encode = temp_df[col].value_counts().to_dict()\n",
    "            \n",
    "    train_df[col+'_total'] = train_df[col].map(fq_encode)\n",
    "    test_df[col+'_total']  = test_df[col].map(fq_encode)\n",
    "    \n",
    "    # We can't use it as solo feature\n",
    "    remove_features.append(col+'_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Start with FE\n",
    "# Before we start with FE I would like to do\n",
    "# few things\n",
    "# 1. Find and reset \"outliers\" for card1 and card2\n",
    "# 2. Create \"Virtual\" client uID\n",
    "# Reset values for \"noise\" card1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare cards 5068\n",
      "No intersection in Train 22360\n",
      "Intersection in Train 395199\n",
      "####################\n",
      "No intersection in Train card2 6102\n",
      "Intersection in Train card2 411457\n",
      "####################\n",
      "No intersection in Train card3 150\n",
      "Intersection in Train card3 417409\n",
      "####################\n",
      "No intersection in Train card4 0\n",
      "Intersection in Train card4 417559\n",
      "####################\n",
      "No intersection in Train card5 7357\n",
      "Intersection in Train card5 410202\n",
      "####################\n",
      "No intersection in Train card6 45\n",
      "Intersection in Train card6 417514\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "########################### Card columns \"outliers\"\n",
    "for col in ['card1']: \n",
    "    valid_card = pd.concat([train_df[[col]], test_df[[col]]])\n",
    "    valid_card = valid_card[col].value_counts()\n",
    "    valid_card_std = valid_card.values.std()\n",
    "\n",
    "    invalid_cards = valid_card[valid_card<=2]\n",
    "    print('Rare cards',len(invalid_cards))\n",
    "\n",
    "    valid_card = valid_card[valid_card>2]\n",
    "    valid_card = list(valid_card.index)\n",
    "\n",
    "    print('No intersection in Train', len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "\n",
    "    train_df[col] = np.where(train_df[col].isin(valid_card), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(valid_card), test_df[col], np.nan)\n",
    "    print('#'*20)\n",
    "\n",
    "for col in ['card2','card3','card4','card5','card6',]: \n",
    "    print('No intersection in Train', col, len(train_df[~train_df[col].isin(test_df[col])]))\n",
    "    print('Intersection in Train', col, len(train_df[train_df[col].isin(test_df[col])]))\n",
    "    \n",
    "    train_df[col] = np.where(train_df[col].isin(test_df[col]), train_df[col], np.nan)\n",
    "    test_df[col]  = np.where(test_df[col].isin(train_df[col]), test_df[col], np.nan)\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Most common uIds:\n",
      "########## uid\n",
      "7919.0_194.0     10393\n",
      "9500.0_321.0      9755\n",
      "nan_555.0         9055\n",
      "15885.0_545.0     7617\n",
      "17188.0_321.0     7158\n",
      "15066.0_170.0     5482\n",
      "6019.0_583.0      5229\n",
      "12695.0_490.0     4833\n",
      "12544.0_321.0     4659\n",
      "2803.0_100.0      4285\n",
      "Name: uid, dtype: int64\n",
      "########## uid2\n",
      "9500.0_321.0_150.0_226.0     9755\n",
      "15885.0_545.0_185.0_138.0    7617\n",
      "17188.0_321.0_150.0_226.0    7158\n",
      "7919.0_194.0_150.0_nan       6047\n",
      "15066.0_170.0_150.0_102.0    5482\n",
      "6019.0_583.0_150.0_226.0     5229\n",
      "nan_555.0_150.0_226.0        5052\n",
      "12695.0_490.0_150.0_226.0    4833\n",
      "12544.0_321.0_150.0_226.0    4659\n",
      "7919.0_194.0_150.0_166.0     4346\n",
      "Name: uid2, dtype: int64\n",
      "########## uid3\n",
      "15885.0_545.0_185.0_138.0_nan_nan       7234\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0    4120\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0    3932\n",
      "3154.0_408.0_185.0_224.0_nan_nan        3306\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0     3140\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0    2435\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0    2416\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0    2414\n",
      "4461.0_375.0_185.0_224.0_nan_nan        1894\n",
      "5812.0_408.0_185.0_224.0_nan_nan        1893\n",
      "Name: uid3, dtype: int64\n",
      "########## uid4\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com     2948\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com       2705\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_gmail.com    1546\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_gmail.com    1432\n",
      "3154.0_408.0_185.0_224.0_nan_nan_hotmail.com      1406\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_gmail.com     1323\n",
      "3154.0_408.0_185.0_224.0_nan_nan_gmail.com        1134\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_gmail.com    1001\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_gmail.com     983\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_yahoo.com     920\n",
      "Name: uid4, dtype: int64\n",
      "########## uid5\n",
      "17188.0_321.0_150.0_226.0_299.0_87.0_nan         3686\n",
      "12695.0_490.0_150.0_226.0_325.0_87.0_nan         3682\n",
      "9500.0_321.0_150.0_226.0_204.0_87.0_nan          2954\n",
      "15885.0_545.0_185.0_138.0_nan_nan_hotmail.com    2948\n",
      "15885.0_545.0_185.0_138.0_nan_nan_gmail.com      2705\n",
      "12839.0_321.0_150.0_226.0_264.0_87.0_nan         2302\n",
      "16132.0_111.0_150.0_226.0_299.0_87.0_nan         2161\n",
      "15497.0_490.0_150.0_226.0_299.0_87.0_nan         2103\n",
      "9500.0_321.0_150.0_226.0_272.0_87.0_nan          1749\n",
      "7664.0_490.0_150.0_226.0_264.0_87.0_nan          1645\n",
      "Name: uid5, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "########################### Client Virtual ID\n",
    "# Let's add some kind of client uID based on cardID and addr columns\n",
    "# The value will be very specific for each client so we need to remove it\n",
    "# from final features. But we can use it for aggregations.\n",
    "train_df['uid'] = train_df['card1'].astype(str)+'_'+train_df['card2'].astype(str)\n",
    "test_df['uid'] = test_df['card1'].astype(str)+'_'+test_df['card2'].astype(str)\n",
    "\n",
    "train_df['uid2'] = train_df['uid'].astype(str)+'_'+train_df['card3'].astype(str)+'_'+train_df['card5'].astype(str)\n",
    "test_df['uid2'] = test_df['uid'].astype(str)+'_'+test_df['card3'].astype(str)+'_'+test_df['card5'].astype(str)\n",
    "\n",
    "train_df['uid3'] = train_df['uid2'].astype(str)+'_'+train_df['addr1'].astype(str)+'_'+train_df['addr2'].astype(str)\n",
    "test_df['uid3'] = test_df['uid2'].astype(str)+'_'+test_df['addr1'].astype(str)+'_'+test_df['addr2'].astype(str)\n",
    "\n",
    "train_df['uid4'] = train_df['uid3'].astype(str)+'_'+train_df['P_emaildomain'].astype(str)\n",
    "test_df['uid4'] = test_df['uid3'].astype(str)+'_'+test_df['P_emaildomain'].astype(str)\n",
    "\n",
    "train_df['uid5'] = train_df['uid3'].astype(str)+'_'+train_df['R_emaildomain'].astype(str)\n",
    "test_df['uid5'] = test_df['uid3'].astype(str)+'_'+test_df['R_emaildomain'].astype(str)\n",
    "\n",
    "# Add values remove list\n",
    "new_columns = ['uid','uid2','uid3','uid4','uid5']\n",
    "remove_features += new_columns\n",
    "\n",
    "print('#'*10)\n",
    "print('Most common uIds:')\n",
    "for col in new_columns:\n",
    "    print('#'*10, col)\n",
    "    print(train_df[col].value_counts()[:10])\n",
    "\n",
    "# Do Global frequency encoding \n",
    "i_cols = ['card1','card2','card3','card5'] + new_columns\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### card3/card5 most common hour \n",
    "# card3 or card5 is a bank country?\n",
    "# can we find:\n",
    "# - the most popular Transaction Hour\n",
    "# - the most popular Week Day\n",
    "# and then find distance from it\n",
    "\n",
    "# Prepare bank type feature\n",
    "for df in [train_df, test_df]:\n",
    "    df['bank_type'] = df['card3'].astype(str) +'_'+ df['card5'].astype(str)\n",
    "remove_features.append('bank_type') \n",
    "\n",
    "encoding_mean = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist','DT_hour_mean'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist','DT_day_week_mean'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist','DT_day_month_mean'],\n",
    "    }\n",
    "\n",
    "encoding_best = {\n",
    "    1: ['DT_D','DT_hour','_hour_dist_best','DT_hour_best'],\n",
    "    2: ['DT_W','DT_day_week','_week_day_dist_best','DT_day_week_best'],\n",
    "    3: ['DT_M','DT_day_month','_month_day_dist_best','DT_day_month_best'],   \n",
    "    }\n",
    "\n",
    "# Some ugly code here (even worse than in other parts)\n",
    "for col in ['card3','card5','bank_type']:\n",
    "    for df in [train_df, test_df]:\n",
    "        for encode in encoding_mean:\n",
    "            encode = encoding_mean[encode].copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "\n",
    "            temp_dict = df.groupby([new_col])[encode[1]].agg(['mean']).reset_index().rename(\n",
    "                                                                    columns={'mean': encode[3]})\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[3]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)\n",
    "\n",
    "        for encode in encoding_best:\n",
    "            encode = encoding_best[encode].copy()\n",
    "            new_col = col + '_' + encode[0] + encode[2]\n",
    "            df[new_col] = df[col].astype(str) +'_'+ df[encode[0]].astype(str)\n",
    "            temp_dict = df.groupby([col,encode[0],encode[1]])[encode[1]].agg(['count']).reset_index().rename(\n",
    "                                                                    columns={'count': encode[3]})\n",
    "\n",
    "            temp_dict.sort_values(by=[col,encode[0],encode[3]], inplace=True)\n",
    "            temp_dict = temp_dict.drop_duplicates(subset=[col,encode[0]], keep='last')\n",
    "            temp_dict[new_col] = temp_dict[col].astype(str) +'_'+ temp_dict[encode[0]].astype(str)\n",
    "            temp_dict.index = temp_dict[new_col].values\n",
    "            temp_dict = temp_dict[encode[1]].to_dict()\n",
    "            df[new_col] = df[encode[1]] - df[new_col].map(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.96451\tvalid_1's auc: 0.898915\n",
      "[400]\ttraining's auc: 0.989972\tvalid_1's auc: 0.912999\n",
      "[600]\ttraining's auc: 0.997288\tvalid_1's auc: 0.917115\n",
      "[800]\ttraining's auc: 0.999256\tvalid_1's auc: 0.918481\n",
      "[1000]\ttraining's auc: 0.999782\tvalid_1's auc: 0.918764\n",
      "Early stopping, best iteration is:\n",
      "[1006]\ttraining's auc: 0.999789\tvalid_1's auc: 0.918809\n",
      "     Value                         Feature\n",
      "0        0                            V107\n",
      "1        0                            V117\n",
      "2        0                            V120\n",
      "3        0                            V241\n",
      "4        0                             V27\n",
      "5        0                             V28\n",
      "6        0                            V305\n",
      "7        0                            V325\n",
      "8        0                             V65\n",
      "9        0                             V88\n",
      "10       0                             V89\n",
      "11       1                            V118\n",
      "12       1                            V240\n",
      "13       1                             V41\n",
      "14       1                             V68\n",
      "15       2                            V119\n",
      "16       3                            V122\n",
      "17       5                            V113\n",
      "18       5                             V14\n",
      "19       6                            V269\n",
      "20       7                            V330\n",
      "21       8                            V104\n",
      "22       8                            V114\n",
      "23       8                            V328\n",
      "24      10                            V196\n",
      "25      11                            V111\n",
      "26      11                            V121\n",
      "27      11                            V302\n",
      "28      12                              V1\n",
      "29      12                            V138\n",
      "..     ...                             ...\n",
      "390   3052       card5_DT_M_month_day_dist\n",
      "391   3134                              D8\n",
      "392   3178                             D10\n",
      "393   3209    bank_type_DT_W_week_day_dist\n",
      "394   3389       card3_DT_M_month_day_dist\n",
      "395   3417       card5_DT_D_hour_dist_best\n",
      "396   3447                              D2\n",
      "397   3476   bank_type_DT_M_month_day_dist\n",
      "398   3624        card3_DT_W_week_day_dist\n",
      "399   3686        bank_type_DT_D_hour_dist\n",
      "400   3691                              D4\n",
      "401   3698       card3_DT_D_hour_dist_best\n",
      "402   3732  card3_DT_M_month_day_dist_best\n",
      "403   3750                             C13\n",
      "404   3832            card5_DT_D_hour_dist\n",
      "405   3852                           dist1\n",
      "406   4247                      uid_fq_enc\n",
      "407   4252            card3_DT_D_hour_dist\n",
      "408   4430  card5_DT_M_month_day_dist_best\n",
      "409   4682                             D15\n",
      "410   4911                    card1_fq_enc\n",
      "411   5676                     uid2_fq_enc\n",
      "412   5886                     uid3_fq_enc\n",
      "413   6423                    card2_fq_enc\n",
      "414   6516                     uid4_fq_enc\n",
      "415   6665                     uid5_fq_enc\n",
      "416   7721                           card2\n",
      "417   8112                           addr1\n",
      "418   8763                  TransactionAmt\n",
      "419  10845                           card1\n",
      "\n",
      "[420 rows x 2 columns]\n",
      "0.9188091201802395\n"
     ]
    }
   ],
   "source": [
    "#### Test new features\n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### D Columns\n",
    "# From columns description we know that\n",
    "# D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "# 1. I can't imagine normal negative timedelta values (Let's clip Values)\n",
    "# 2. Normalize (Min-Max, Standard score) All D columns, except D1,D2,D9\n",
    "# 3. Do some aggregations based on uIDs\n",
    "# 4. Freaquency encoding\n",
    "# 5. D1,D2 are clipped by max train_df values (let's scale it)\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "uids = ['uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "####### uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    "\n",
    "####### Cleaning Neagtive values and columns transformations\n",
    "for df in [train_df, test_df]:\n",
    "\n",
    "    for col in i_cols:\n",
    "        df[col] = df[col].clip(0) \n",
    "    \n",
    "    # Lets transform D8 and D9 column\n",
    "    # As we almost sure it has connection with hours\n",
    "    df['D9_not_na'] = np.where(df['D9'].isna(),0,1)\n",
    "    df['D8_not_same_day'] = np.where(df['D8']>=1,1,0)\n",
    "    df['D8_D9_decimal_dist'] = df['D8'].fillna(0)-df['D8'].fillna(0).astype(int)\n",
    "    df['D8_D9_decimal_dist'] = ((df['D8_D9_decimal_dist']-df['D9'])**2)**0.5\n",
    "    df['D8'] = df['D8'].fillna(-1).astype(int)\n",
    "\n",
    "####### Values Normalization\n",
    "i_cols.remove('D1')\n",
    "i_cols.remove('D2')\n",
    "i_cols.remove('D9')\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "for col in ['D1','D2']:\n",
    "    for df in [train_df, test_df]:\n",
    "        df[col+'_scaled'] = df[col]/train_df[col].max()\n",
    "        \n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "i_cols = ['D'+str(i) for i in range(1,16)]\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.97753\tvalid_1's auc: 0.905101\n",
      "[400]\ttraining's auc: 0.995803\tvalid_1's auc: 0.918242\n",
      "[600]\ttraining's auc: 0.999217\tvalid_1's auc: 0.921836\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttraining's auc: 0.999451\tvalid_1's auc: 0.922337\n",
      "     Value                         Feature\n",
      "0        0                 D8_not_same_day\n",
      "1        0                            V107\n",
      "2        0                            V117\n",
      "3        0                            V118\n",
      "4        0                            V119\n",
      "5        0                            V120\n",
      "6        0                            V121\n",
      "7        0                            V122\n",
      "8        0                             V14\n",
      "9        0                            V241\n",
      "10       0                             V27\n",
      "11       0                             V28\n",
      "12       0                            V305\n",
      "13       0                            V325\n",
      "14       0                             V41\n",
      "15       0                             V65\n",
      "16       0                             V68\n",
      "17       0                             V89\n",
      "18       1                       D9_not_na\n",
      "19       1                              V1\n",
      "20       1                            V104\n",
      "21       1                            V113\n",
      "22       1                            V138\n",
      "23       1                            V157\n",
      "24       1                            V269\n",
      "25       1                            V297\n",
      "26       1                            V302\n",
      "27       1                             V31\n",
      "28       1                            V328\n",
      "29       1                             V88\n",
      "..     ...                             ...\n",
      "647    902                    uid5_D3_mean\n",
      "648    911               D4_DT_D_std_score\n",
      "649    924                    uid4_D11_std\n",
      "650    925                     uid3_D5_std\n",
      "651    935                    uid4_D15_std\n",
      "652    936                           dist1\n",
      "653    937                    uid5_D5_mean\n",
      "654    943                    uid4_D8_mean\n",
      "655    971                    uid5_D9_mean\n",
      "656    986                     uid3_D9_std\n",
      "657    995                    uid3_D8_mean\n",
      "658   1006                    uid4_D9_mean\n",
      "659   1028                     uid4_D3_std\n",
      "660   1033                    uid5_D8_mean\n",
      "661   1043  card5_DT_M_month_day_dist_best\n",
      "662   1080              D10_DT_D_std_score\n",
      "663   1101                    uid4_D5_mean\n",
      "664   1116              D15_DT_D_std_score\n",
      "665   1131                           addr1\n",
      "666   1132                     uid4_D5_std\n",
      "667   1139                           card2\n",
      "668   1151                    uid4_D2_mean\n",
      "669   1163                   P_emaildomain\n",
      "670   1169                     uid4_D2_std\n",
      "671   1183                    uid4_D3_mean\n",
      "672   1189               D8_DT_D_std_score\n",
      "673   1235                              C1\n",
      "674   1562                             C13\n",
      "675   1737                           card1\n",
      "676   2857                  TransactionAmt\n",
      "\n",
      "[677 rows x 2 columns]\n",
      "0.9223370621289021\n"
     ]
    }
   ],
   "source": [
    "#### Test new features\n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################### TransactionAmt\n",
    "i_cols = ['TransactionAmt']\n",
    "periods = ['DT_D']\n",
    "\n",
    "temp_df = pd.concat([train_df[['TransactionDT']+i_cols+periods], test_df[['TransactionDT']+i_cols+periods]])\n",
    "for period in periods:\n",
    "    for col in i_cols:\n",
    "        for df in [temp_df]:\n",
    "            df.set_index(period)[col].plot(style='.', title=col, figsize=(15, 3))\n",
    "            plt.show()\n",
    "\n",
    "# Clip Values\n",
    "train_df['TransactionAmt'] = train_df['TransactionAmt'].clip(0,5000)\n",
    "test_df['TransactionAmt']  = test_df['TransactionAmt'].clip(0,5000)\n",
    "\n",
    "# Check if the Transaction Amount is common or not (we can use freq encoding here)\n",
    "# In our dialog with a model we are telling to trust or not to these values   \n",
    "train_df['TransactionAmt_check'] = np.where(train_df['TransactionAmt'].isin(test_df['TransactionAmt']), 1, 0)\n",
    "test_df['TransactionAmt_check']  = np.where(test_df['TransactionAmt'].isin(train_df['TransactionAmt']), 1, 0)\n",
    "\n",
    "# For our model current TransactionAmt is a noise\n",
    "# https://www.kaggle.com/kyakovlev/ieee-check-noise\n",
    "# (even if features importances are telling contrariwise)\n",
    "# There are many unique values and model doesn't generalize well\n",
    "# Lets do some aggregations\n",
    "i_cols = ['TransactionAmt']\n",
    "uids = ['card1','card2','card3','card5','uid','uid2','uid3','uid4','uid5','bank_type']\n",
    "aggregations = ['mean','std']\n",
    "\n",
    "# uIDs aggregations\n",
    "train_df, test_df = uid_aggregation(train_df, test_df, i_cols, uids, aggregations)\n",
    " \n",
    "# TransactionAmt Normalization\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "for df in [train_df, test_df]:\n",
    "    df = values_normalization(df, periods, i_cols)\n",
    "\n",
    "# Product type\n",
    "train_df['product_type'] = train_df['ProductCD'].astype(str)+'_'+train_df['TransactionAmt'].astype(str)\n",
    "test_df['product_type'] = test_df['ProductCD'].astype(str)+'_'+test_df['TransactionAmt'].astype(str)\n",
    "\n",
    "i_cols = ['product_type']\n",
    "periods = ['DT_D','DT_W','DT_M']\n",
    "train_df, test_df = timeblock_frequency_encoding(train_df, test_df, periods, i_cols, \n",
    "                                                 with_proportions=False, only_proportions=True)\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)\n",
    "\n",
    "# Small \"hack\" to transform distribution \n",
    "# (doesn't affect auc much, but I like it more)\n",
    "# please see how distribution transformation can boost your score \n",
    "# (not our case but related)\n",
    "# https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html\n",
    "train_df['TransactionAmt'] = np.log1p(train_df['TransactionAmt'])\n",
    "test_df['TransactionAmt'] = np.log1p(test_df['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.979151\tvalid_1's auc: 0.907633\n",
      "[400]\ttraining's auc: 0.996455\tvalid_1's auc: 0.919401\n",
      "[600]\ttraining's auc: 0.999385\tvalid_1's auc: 0.923028\n",
      "[800]\ttraining's auc: 0.999878\tvalid_1's auc: 0.923613\n",
      "Early stopping, best iteration is:\n",
      "[896]\ttraining's auc: 0.999947\tvalid_1's auc: 0.923843\n",
      "     Value                         Feature\n",
      "0        0                            V107\n",
      "1        0                            V118\n",
      "2        0                            V119\n",
      "3        0                            V120\n",
      "4        0                            V241\n",
      "5        0                            V269\n",
      "6        0                             V27\n",
      "7        0                             V28\n",
      "8        0                            V305\n",
      "9        0                            V325\n",
      "10       0                             V41\n",
      "11       0                             V68\n",
      "12       0                             V88\n",
      "13       0                             V89\n",
      "14       1                       D9_not_na\n",
      "15       1                              V1\n",
      "16       1                            V113\n",
      "17       1                            V117\n",
      "18       1                            V122\n",
      "19       1                            V138\n",
      "20       1                             V14\n",
      "21       1                            V302\n",
      "22       2                 D8_not_same_day\n",
      "23       2                            V284\n",
      "24       2                             V31\n",
      "25       2                            V334\n",
      "26       2                             V50\n",
      "27       2                             V65\n",
      "28       2                              V8\n",
      "29       3                            V114\n",
      "..     ...                             ...\n",
      "678   1191       card3_DT_D_hour_dist_best\n",
      "679   1225                    product_type\n",
      "680   1227                     uid4_D5_std\n",
      "681   1228                     uid3_D9_std\n",
      "682   1229            card3_DT_D_hour_dist\n",
      "683   1243                    uid3_D8_mean\n",
      "684   1252     TransactionAmt_DT_W_min_max\n",
      "685   1262                    uid5_D8_mean\n",
      "686   1271                    uid4_D8_mean\n",
      "687   1272                    uid4_D9_mean\n",
      "688   1281  card5_DT_M_month_day_dist_best\n",
      "689   1285               D4_DT_D_std_score\n",
      "690   1364                    uid4_D5_mean\n",
      "691   1375                    uid4_D2_mean\n",
      "692   1384     TransactionAmt_DT_D_min_max\n",
      "693   1389                              C1\n",
      "694   1409                   P_emaildomain\n",
      "695   1444                    uid4_D3_mean\n",
      "696   1446   TransactionAmt_DT_D_std_score\n",
      "697   1457                     uid4_D2_std\n",
      "698   1477                           addr1\n",
      "699   1480               product_type_DT_M\n",
      "700   1492              D10_DT_D_std_score\n",
      "701   1560              D15_DT_D_std_score\n",
      "702   1580               product_type_DT_W\n",
      "703   1630               D8_DT_D_std_score\n",
      "704   1634         uid4_TransactionAmt_std\n",
      "705   1839                             C13\n",
      "706   1944                           card1\n",
      "707   2025               product_type_DT_D\n",
      "\n",
      "[708 rows x 2 columns]\n",
      "0.9238427006765387\n"
     ]
    }
   ],
   "source": [
    "#### Test new features\n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Device info and identity\n",
    "for df in [train_identity, test_identity]:\n",
    "    ########################### Device info\n",
    "    df['DeviceInfo'] = df['DeviceInfo'].fillna('unknown_device').str.lower()\n",
    "    df['DeviceInfo_device'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['DeviceInfo_version'] = df['DeviceInfo'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Device info 2\n",
    "    df['id_30'] = df['id_30'].fillna('unknown_device').str.lower()\n",
    "    df['id_30_device'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    df['id_30_version'] = df['id_30'].apply(lambda x: ''.join([i for i in x if i.isnumeric()]))\n",
    "    \n",
    "    ########################### Browser\n",
    "    df['id_31'] = df['id_31'].fillna('unknown_device').str.lower()\n",
    "    df['id_31_device'] = df['id_31'].apply(lambda x: ''.join([i for i in x if i.isalpha()]))\n",
    "    \n",
    "########################### Merge Identity columns\n",
    "temp_df = train_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(train_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "train_df = pd.concat([train_df,temp_df], axis=1)\n",
    "    \n",
    "temp_df = test_df[['TransactionID']]\n",
    "temp_df = temp_df.merge(test_identity, on=['TransactionID'], how='left')\n",
    "del temp_df['TransactionID']\n",
    "test_df = pd.concat([test_df,temp_df], axis=1)\n",
    "\n",
    "i_cols = [\n",
    "          'DeviceInfo','DeviceInfo_device','DeviceInfo_version',\n",
    "          'id_30','id_30_device','id_30_version',\n",
    "          'id_31','id_31_device',\n",
    "          'id_33',\n",
    "         ]\n",
    "\n",
    "####### Global Self frequency encoding\n",
    "# self_encoding=True because \n",
    "# we don't need original values anymore\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, i_cols, self_encoding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.979586\tvalid_1's auc: 0.908309\n",
      "[400]\ttraining's auc: 0.996828\tvalid_1's auc: 0.920131\n",
      "[600]\ttraining's auc: 0.999504\tvalid_1's auc: 0.923924\n",
      "[800]\ttraining's auc: 0.999913\tvalid_1's auc: 0.924297\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's auc: 0.999833\tvalid_1's auc: 0.924508\n",
      "     Value                         Feature\n",
      "0        0                       D9_not_na\n",
      "1        0                            V107\n",
      "2        0                            V113\n",
      "3        0                            V117\n",
      "4        0                            V118\n",
      "5        0                            V119\n",
      "6        0                            V120\n",
      "7        0                            V122\n",
      "8        0                             V14\n",
      "9        0                            V241\n",
      "10       0                             V27\n",
      "11       0                             V28\n",
      "12       0                            V284\n",
      "13       0                            V305\n",
      "14       0                             V31\n",
      "15       0                            V325\n",
      "16       0                             V41\n",
      "17       0                             V65\n",
      "18       0                             V68\n",
      "19       0                             V88\n",
      "20       0                             V89\n",
      "21       0                           id_27\n",
      "22       1                 D8_not_same_day\n",
      "23       1                            V101\n",
      "24       1                            V121\n",
      "25       1                            V157\n",
      "26       1                             V21\n",
      "27       1                            V240\n",
      "28       1                            V269\n",
      "29       1                            V302\n",
      "..     ...                             ...\n",
      "723    956                       D2_scaled\n",
      "724    956                    uid4_D8_mean\n",
      "725    957                     uid4_D4_std\n",
      "726    962               D4_DT_D_std_score\n",
      "727    962                     uid3_D9_std\n",
      "728    971                    uid3_D8_mean\n",
      "729    979                    uid4_D9_mean\n",
      "730   1002                     uid4_D3_std\n",
      "731   1003  card5_DT_M_month_day_dist_best\n",
      "732   1015   TransactionAmt_DT_D_std_score\n",
      "733   1036     TransactionAmt_DT_D_min_max\n",
      "734   1043                    uid4_D2_mean\n",
      "735   1046                           id_02\n",
      "736   1046                    uid5_D8_mean\n",
      "737   1052               product_type_DT_M\n",
      "738   1104              D10_DT_D_std_score\n",
      "739   1118                     uid4_D5_std\n",
      "740   1137                   P_emaildomain\n",
      "741   1155              D15_DT_D_std_score\n",
      "742   1161               product_type_DT_W\n",
      "743   1167                           addr1\n",
      "744   1186                    uid4_D5_mean\n",
      "745   1203               D8_DT_D_std_score\n",
      "746   1216                     uid4_D2_std\n",
      "747   1244                    uid4_D3_mean\n",
      "748   1253         uid4_TransactionAmt_std\n",
      "749   1267                              C1\n",
      "750   1454                           card1\n",
      "751   1479                             C13\n",
      "752   1493               product_type_DT_D\n",
      "\n",
      "[753 rows x 2 columns]\n",
      "0.9245076087770493\n"
     ]
    }
   ],
   "source": [
    "#### Test new features\n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = train_df.copy()\n",
    "te = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductCD\n",
      "card4\n",
      "card6\n",
      "P_emaildomain\n",
      "R_emaildomain\n",
      "M1\n",
      "M2\n",
      "M3\n",
      "M4\n",
      "M5\n",
      "M6\n",
      "M7\n",
      "M8\n",
      "M9\n",
      "uid\n",
      "uid2\n",
      "uid3\n",
      "uid4\n",
      "uid5\n",
      "bank_type\n",
      "id_12\n",
      "id_15\n",
      "id_16\n",
      "id_23\n",
      "id_27\n",
      "id_28\n",
      "id_29\n",
      "id_34\n",
      "id_35\n",
      "id_36\n",
      "id_37\n",
      "id_38\n",
      "DeviceType\n"
     ]
    }
   ],
   "source": [
    "########################### Encode Str columns\n",
    "# For all such columns (probably not)\n",
    "# we already did frequency encoding (numeric feature)\n",
    "# so we will use astype('category') here\n",
    "for col in list(train_df):\n",
    "    if train_df[col].dtype=='O':\n",
    "        print(col)\n",
    "        train_df[col] = train_df[col].fillna('unseen_before_label')\n",
    "        test_df[col]  = test_df[col].fillna('unseen_before_label')\n",
    "        \n",
    "        train_df[col] = train_df[col].astype(str)\n",
    "        test_df[col] = test_df[col].astype(str)\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train_df[col])+list(test_df[col]))\n",
    "        train_df[col] = le.transform(train_df[col])\n",
    "        test_df[col]  = le.transform(test_df[col])\n",
    "        \n",
    "        train_df[col] = train_df[col].astype('category')\n",
    "        test_df[col] = test_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.979586\tvalid_1's auc: 0.908309\n",
      "[400]\ttraining's auc: 0.996828\tvalid_1's auc: 0.920131\n",
      "[600]\ttraining's auc: 0.999504\tvalid_1's auc: 0.923924\n",
      "[800]\ttraining's auc: 0.999913\tvalid_1's auc: 0.924297\n",
      "Early stopping, best iteration is:\n",
      "[726]\ttraining's auc: 0.999833\tvalid_1's auc: 0.924508\n",
      "     Value                         Feature\n",
      "0        0                       D9_not_na\n",
      "1        0                            V107\n",
      "2        0                            V113\n",
      "3        0                            V117\n",
      "4        0                            V118\n",
      "5        0                            V119\n",
      "6        0                            V120\n",
      "7        0                            V122\n",
      "8        0                             V14\n",
      "9        0                            V241\n",
      "10       0                             V27\n",
      "11       0                             V28\n",
      "12       0                            V284\n",
      "13       0                            V305\n",
      "14       0                             V31\n",
      "15       0                            V325\n",
      "16       0                             V41\n",
      "17       0                             V65\n",
      "18       0                             V68\n",
      "19       0                             V88\n",
      "20       0                             V89\n",
      "21       0                           id_27\n",
      "22       1                 D8_not_same_day\n",
      "23       1                            V101\n",
      "24       1                            V121\n",
      "25       1                            V157\n",
      "26       1                             V21\n",
      "27       1                            V240\n",
      "28       1                            V269\n",
      "29       1                            V302\n",
      "..     ...                             ...\n",
      "723    956                       D2_scaled\n",
      "724    956                    uid4_D8_mean\n",
      "725    957                     uid4_D4_std\n",
      "726    962               D4_DT_D_std_score\n",
      "727    962                     uid3_D9_std\n",
      "728    971                    uid3_D8_mean\n",
      "729    979                    uid4_D9_mean\n",
      "730   1002                     uid4_D3_std\n",
      "731   1003  card5_DT_M_month_day_dist_best\n",
      "732   1015   TransactionAmt_DT_D_std_score\n",
      "733   1036     TransactionAmt_DT_D_min_max\n",
      "734   1043                    uid4_D2_mean\n",
      "735   1046                           id_02\n",
      "736   1046                    uid5_D8_mean\n",
      "737   1052               product_type_DT_M\n",
      "738   1104              D10_DT_D_std_score\n",
      "739   1118                     uid4_D5_std\n",
      "740   1137                   P_emaildomain\n",
      "741   1155              D15_DT_D_std_score\n",
      "742   1161               product_type_DT_W\n",
      "743   1167                           addr1\n",
      "744   1186                    uid4_D5_mean\n",
      "745   1203               D8_DT_D_std_score\n",
      "746   1216                     uid4_D2_std\n",
      "747   1244                    uid4_D3_mean\n",
      "748   1253         uid4_TransactionAmt_std\n",
      "749   1267                              C1\n",
      "750   1454                           card1\n",
      "751   1479                             C13\n",
      "752   1493               product_type_DT_D\n",
      "\n",
      "[753 rows x 2 columns]\n",
      "0.9245076087770493\n"
     ]
    }
   ],
   "source": [
    "#### Test new features\n",
    "if MAKE_MODEL_TEST:\n",
    "    test_predictions = make_test_predictions(train_df, test_df, TARGET, lgb_params)\n",
    "    print(metrics.roc_auc_score(test_predictions[TARGET], test_predictions['prediction']))\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Minification\n",
    "train_df.to_csv('train_df.csv')\n",
    "test_df.to_csv('test_df.csv')\n",
    "\n",
    "remove_features = pd.DataFrame(remove_features, columns=['features_to_remove'])\n",
    "remove_features.to_csv('remove_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
