{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, warnings, random, datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model\n",
    "import lightgbm as lgb\n",
    "\n",
    "def make_predictions(tr_df, tt_df, features_columns, target, lgb_params, NFOLDS=2):\n",
    "    \n",
    "    folds = GroupKFold(n_splits=NFOLDS)\n",
    "\n",
    "    X,y = tr_df[features_columns], tr_df[target]    \n",
    "    P,P_y = tt_df[features_columns], tt_df[target]  \n",
    "    split_groups = tr_df['DT_M']\n",
    "\n",
    "    tt_df = tt_df[['TransactionID',target]]    \n",
    "    predictions = np.zeros(len(tt_df))\n",
    "    oof = np.zeros(len(tr_df))\n",
    "    \n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups=split_groups)):\n",
    "        print('Fold:',fold_)\n",
    "        tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n",
    "        vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n",
    "            \n",
    "        print(len(tr_x),len(vl_x))\n",
    "        tr_data = lgb.Dataset(tr_x, label=tr_y)\n",
    "        vl_data = lgb.Dataset(vl_x, label=vl_y)  \n",
    "\n",
    "        estimator = lgb.train(\n",
    "            lgb_params,\n",
    "            tr_data,\n",
    "            valid_sets = [tr_data, vl_data],\n",
    "            verbose_eval = 200,\n",
    "        )   \n",
    "        \n",
    "        pp_p = estimator.predict(P)\n",
    "        predictions += pp_p/NFOLDS\n",
    "        \n",
    "        oof_preds = estimator.predict(vl_x)\n",
    "        oof[val_idx] = (oof_preds - oof_preds.min())/(oof_preds.max() - oof_preds.min())\n",
    "\n",
    "        if LOCAL_TEST:\n",
    "            feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\n",
    "            print(feature_imp)\n",
    "        \n",
    "        del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n",
    "        gc.collect()\n",
    "        \n",
    "    tt_df['prediction'] = predictions\n",
    "    print('OOF AUC:', metrics.roc_auc_score(y, oof))\n",
    "    if LOCAL_TEST:\n",
    "        print('Holdout AUC:', metrics.roc_auc_score(tt_df[TARGET], tt_df['prediction']))\n",
    "    \n",
    "    return tt_df\n",
    "## -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "LOCAL_TEST = False\n",
    "TARGET = 'isFraud'\n",
    "START_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "lgb_params = {\n",
    "                    'objective':'binary',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'auc',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.01,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.5,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "Shape control: (417559, 773) (89326, 773)\n"
     ]
    }
   ],
   "source": [
    "########################### DATA LOAD\n",
    "#################################################################################\n",
    "print('Load Data')\n",
    "\n",
    "if LOCAL_TEST:\n",
    "    train_df = pd.read_csv('train_df.csv')\n",
    "    test_df = pd.read_csv('test_df.csv') \n",
    "else:\n",
    "    train_df = pd.read_csv('train_df.csv')\n",
    "    test_df = pd.read_csv('test_df.csv')\n",
    "    \n",
    "remove_features = pd.read_csv('remove_features.csv')\n",
    "remove_features = list(remove_features['features_to_remove'].values)\n",
    "print('Shape control:', train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 648.69 Mb (73.7% reduction)\n",
      "Mem. usage decreased to 141.50 Mb (73.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "########################### Final features list\n",
    "features_columns = [col for col in list(train_df) if col not in remove_features]\n",
    "\n",
    "########################### Final Minification\n",
    "## I don't like this part as it changes float numbers\n",
    "## small change but change.\n",
    "## To be able to train lgbm without \n",
    "## minification we need to do some changes on model\n",
    "## we will do it later.\n",
    "if not LOCAL_TEST:\n",
    "    train_df = reduce_mem_usage(train_df)\n",
    "    test_df  = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "280238 137321\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.973378\tvalid_1's auc: 0.87937\n",
      "[400]\ttraining's auc: 0.993853\tvalid_1's auc: 0.892732\n",
      "[600]\ttraining's auc: 0.998825\tvalid_1's auc: 0.898872\n",
      "[800]\ttraining's auc: 0.999747\tvalid_1's auc: 0.902787\n",
      "[1000]\ttraining's auc: 0.999947\tvalid_1's auc: 0.905838\n",
      "[1200]\ttraining's auc: 0.999991\tvalid_1's auc: 0.908145\n",
      "[1400]\ttraining's auc: 0.999999\tvalid_1's auc: 0.909594\n",
      "[1600]\ttraining's auc: 1\tvalid_1's auc: 0.91089\n",
      "[1800]\ttraining's auc: 1\tvalid_1's auc: 0.911172\n",
      "Early stopping, best iteration is:\n",
      "[1896]\ttraining's auc: 1\tvalid_1's auc: 0.911483\n",
      "Fold: 1\n",
      "315927 101632\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.973807\tvalid_1's auc: 0.908649\n",
      "[400]\ttraining's auc: 0.994462\tvalid_1's auc: 0.922992\n",
      "[600]\ttraining's auc: 0.999081\tvalid_1's auc: 0.928493\n",
      "[800]\ttraining's auc: 0.999819\tvalid_1's auc: 0.930647\n",
      "[1000]\ttraining's auc: 0.999962\tvalid_1's auc: 0.931736\n",
      "[1200]\ttraining's auc: 0.999994\tvalid_1's auc: 0.93239\n",
      "Early stopping, best iteration is:\n",
      "[1210]\ttraining's auc: 0.999995\tvalid_1's auc: 0.932447\n",
      "Fold: 2\n",
      "324974 92585\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.968365\tvalid_1's auc: 0.917246\n",
      "[400]\ttraining's auc: 0.993143\tvalid_1's auc: 0.932369\n",
      "[600]\ttraining's auc: 0.998708\tvalid_1's auc: 0.939664\n",
      "[800]\ttraining's auc: 0.999715\tvalid_1's auc: 0.942464\n",
      "[1000]\ttraining's auc: 0.999934\tvalid_1's auc: 0.944192\n",
      "[1200]\ttraining's auc: 0.999988\tvalid_1's auc: 0.944955\n",
      "[1400]\ttraining's auc: 0.999999\tvalid_1's auc: 0.945254\n",
      "Early stopping, best iteration is:\n",
      "[1350]\ttraining's auc: 0.999998\tvalid_1's auc: 0.945331\n",
      "Fold: 3\n",
      "331538 86021\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's auc: 0.969455\tvalid_1's auc: 0.928334\n",
      "[400]\ttraining's auc: 0.992848\tvalid_1's auc: 0.941253\n",
      "[600]\ttraining's auc: 0.998496\tvalid_1's auc: 0.945659\n",
      "[800]\ttraining's auc: 0.999651\tvalid_1's auc: 0.947607\n",
      "[1000]\ttraining's auc: 0.999912\tvalid_1's auc: 0.94844\n",
      "[1200]\ttraining's auc: 0.999981\tvalid_1's auc: 0.949099\n",
      "Early stopping, best iteration is:\n",
      "[1240]\ttraining's auc: 0.999986\tvalid_1's auc: 0.949196\n",
      "OOF AUC: 0.9330522957752103\n"
     ]
    }
   ],
   "source": [
    "########################### Model Train\n",
    "if LOCAL_TEST:\n",
    "    lgb_params['learning_rate'] = 0.01\n",
    "    lgb_params['n_estimators'] = 10000\n",
    "    lgb_params['early_stopping_rounds'] = 100\n",
    "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=4)\n",
    "else:\n",
    "    lgb_params['learning_rate'] = 0.007\n",
    "    lgb_params['n_estimators'] = 10000\n",
    "    lgb_params['early_stopping_rounds'] = 100    \n",
    "    test_predictions = make_predictions(train_df, test_df, features_columns, TARGET, lgb_params, NFOLDS=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "if not LOCAL_TEST:\n",
    "    test_predictions['isFraud'] = test_predictions['prediction']\n",
    "    test_predictions[['TransactionID','isFraud']].to_csv('./outputs./prediction_/submission_Group_0.9330.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89326, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
